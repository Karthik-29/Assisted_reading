{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ebooklib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHAsgHxjxD-N",
        "outputId": "ec3e4a08-989c-410d-ded0-4a3c3aaa21ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ebooklib\n",
            "  Downloading EbookLib-0.18.tar.gz (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.5/115.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from ebooklib) (4.9.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from ebooklib) (1.16.0)\n",
            "Building wheels for collected packages: ebooklib\n",
            "  Building wheel for ebooklib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ebooklib: filename=EbookLib-0.18-py3-none-any.whl size=38778 sha256=3c97b6d2cfee8417e1b82b0f55ba4eb8f6ee1e983fe7aba324f53c2a22d7fa00\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/38/cc/a3728bb72a315d9d8766fb71d362136372066fc25ad838f8fa\n",
            "Successfully built ebooklib\n",
            "Installing collected packages: ebooklib\n",
            "Successfully installed ebooklib-0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGxtMYmTwhcA",
        "outputId": "12f8b372-96e0-4bdf-81de-823cddfce38c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import ebooklib\n",
        "from ebooklib import epub\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import html\n",
        "from google.colab import drive\n",
        "import random\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from html import escape\n",
        "\n",
        "def process_text(token):\n",
        "    if token.lower() not in stop_words:\n",
        "        stemmed_token = stemmer.stem(token)\n",
        "        #stemmed_token = token[:int(random.randint(1,len(token))*0.8)]\n",
        "        extra = token[len(stemmed_token):] if len(stemmed_token) < len(token) else ''\n",
        "    else:\n",
        "        stemmed_token = None\n",
        "        extra = ''\n",
        "    res = ''\n",
        "    if stemmed_token:\n",
        "        res += '<b>{}</b>{}'.format(escape(stemmed_token), extra)\n",
        "    else:\n",
        "        res += escape(token)\n",
        "    return res"
      ],
      "metadata": {
        "id": "RsumLljtxNGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_epub(input_epub_path):\n",
        "    # Load EPUB file\n",
        "    book = epub.read_epub(input_epub_path)\n",
        "\n",
        "    # Iterate through each item in the book\n",
        "    for item in book.get_items():\n",
        "        # Check if the item is of type 'text'\n",
        "        if item.get_type() == ebooklib.ITEM_DOCUMENT:\n",
        "            # Get the content of the item\n",
        "            content = item.get_content().decode('utf-8')\n",
        "\n",
        "            # Use BeautifulSoup to parse HTML content\n",
        "            soup = BeautifulSoup(content, 'html.parser')\n",
        "\n",
        "            # Find and process each word within the HTML tags\n",
        "            for tag in soup.find_all():\n",
        "                if tag.name and tag.name not in ['style', 'script']:\n",
        "                    # Tokenize words using NLTK\n",
        "                    words = word_tokenize(tag.get_text())\n",
        "\n",
        "                    # Process and replace each word\n",
        "                    for i, word in enumerate(words):\n",
        "                        transformed_word = process_text(word)\n",
        "                        words[i] = transformed_word\n",
        "\n",
        "                    # Replace the original content with the modified content\n",
        "                    if tag.string is not None and ' '.join(words):\n",
        "                        new_content = BeautifulSoup(' '.join(words), 'html.parser')\n",
        "                        if new_content is not None:\n",
        "                            tag.contents = new_content.contents\n",
        "\n",
        "\n",
        "\n",
        "            # Update the content with preserved HTML structure\n",
        "            item.content = str(soup).encode('utf-8')\n",
        "\n",
        "    # Save the modified EPUB to the current working directory\n",
        "    output_epub_path = os.path.join('your/path', 'your_book.epub')\n",
        "    epub.write_epub(output_epub_path, book)"
      ],
      "metadata": {
        "id": "8gI7QeFvxav8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('yor/path')\n",
        "\n",
        "# Manually specify the input EPUB file path in Google Drive\n",
        "input_epub_path = 'your/path/transformed_book.epub'\n",
        "book = epub.read_epub(input_epub_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBbE8mwyO2ig",
        "outputId": "05d607c7-491a-49c6-87a2-110c4942254a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ebooklib/epub.py:1395: UserWarning: In the future version we will turn default option ignore_ncx to True.\n",
            "  warnings.warn('In the future version we will turn default option ignore_ncx to True.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform_epub(input_epub_path)"
      ],
      "metadata": {
        "id": "fXlLuf1pbsFT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}